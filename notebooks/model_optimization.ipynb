{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fa62d87",
   "metadata": {},
   "source": [
    "\n",
    "# Model Optimization\n",
    "\n",
    "This notebook optimizes all models used in the training phase. For each model, we:\n",
    "1. Perform hyperparameter tuning using GridSearchCV.\n",
    "2. Evaluate the optimized models compared to the default models.\n",
    "3. Visualize results, including performance metrics and confusion matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "0b2d5282",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T16:07:32.832285Z",
     "start_time": "2024-12-03T16:07:32.607946Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "data = pd.read_csv(\"../data/processed/scaled_results/Employee_MedianMode_imputed_standard_scaled.csv\")\n",
    "\n",
    "X = data.drop(columns=['LeaveOrNot'])\n",
    "y = data['LeaveOrNot'].astype(int)\n",
    "\n",
    "def manual_train_test_split(X, y, test_size=0.2, random_state=10):\n",
    "    np.random.seed(random_state)\n",
    "    indices = np.random.permutation(len(X))\n",
    "    test_set_size = int(len(X) * test_size)\n",
    "    test_indices = indices[:test_set_size]\n",
    "    train_indices = indices[test_set_size:]\n",
    "    return X.iloc[train_indices], X.iloc[test_indices], y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "X_train, X_test, y_train, y_test = manual_train_test_split(X, y, test_size=0.2, random_state=10)\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_correlation_matrix(X):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    corr_matrix = X.corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "    plt.title(\"Feature Correlation Matrix\")\n",
    "    plt.show()\n",
    "    return corr_matrix"
   ],
   "id": "dbcd27bd638a4d27"
  },
  {
   "cell_type": "code",
   "id": "80e0d29f4624bb7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T16:07:33.093019Z",
     "start_time": "2024-12-03T16:07:32.832878Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T16:07:41.476415Z",
     "start_time": "2024-12-03T16:07:33.094649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Random Forest\n",
    "rf_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "rf_search = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=10), param_grid=rf_grid, scoring='f1', cv=3\n",
    ")\n",
    "rf_search.fit(X_train, y_train)\n",
    "optimized_results['Random Forest'] = rf_search.best_params_"
   ],
   "id": "1427509f3622c368",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T16:07:43.107170Z",
     "start_time": "2024-12-03T16:07:41.477062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SVM\n",
    "svm_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "svm_search = GridSearchCV(\n",
    "    SVC(random_state=10), param_grid=svm_grid, scoring='f1', cv=3\n",
    ")\n",
    "svm_search.fit(X_train, y_train)\n",
    "optimized_results['SVM'] = svm_search.best_params_"
   ],
   "id": "d4399b038009ba71",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T16:07:54.973041Z",
     "start_time": "2024-12-03T16:07:43.107910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# XGBoost\n",
    "xgb_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 6, 9]\n",
    "}\n",
    "xgb_search = GridSearchCV(\n",
    "    XGBClassifier(random_state=10, eval_metric='logloss'),\n",
    "    param_grid=xgb_grid, scoring='f1', cv=3\n",
    ")\n",
    "xgb_search.fit(X_train, y_train)\n",
    "optimized_results['XGBoost'] = xgb_search.best_params_"
   ],
   "id": "b939b8e53305172b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T16:08:39.770048Z",
     "start_time": "2024-12-03T16:07:54.973671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# LightGBM\n",
    "lgbm_grid = {\n",
    "    'num_leaves': [15, 31, 63],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [50, 100, 200]\n",
    "}\n",
    "lgbm_search = GridSearchCV(\n",
    "    LGBMClassifier(random_state=10), param_grid=lgbm_grid, scoring='f1', cv=3\n",
    ")\n",
    "lgbm_search.fit(X_train, y_train)\n",
    "optimized_results['LightGBM'] = lgbm_search.best_params_\n",
    "\n",
    "print(\"Optimized Hyperparameters:\")\n",
    "for model, params in optimized_results.items():\n",
    "    print(f\"{model}: {params}\")\n"
   ],
   "id": "eb6eb7c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000326 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000340 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000298 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000314 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000534 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 750, number of negative: 1732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302176 -> initscore=-0.836959\n",
      "[LightGBM] [Info] Start training from score -0.836959\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 749, number of negative: 1733\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 2482, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301773 -> initscore=-0.838870\n",
      "[LightGBM] [Info] Start training from score -0.838870\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1124, number of negative: 2599\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 3723, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301907 -> initscore=-0.838233\n",
      "[LightGBM] [Info] Start training from score -0.838233\n",
      "Optimized Hyperparameters:\n",
      "Logistic Regression: {'C': 1}\n",
      "Random Forest: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "SVM: {'C': 10, 'kernel': 'rbf'}\n",
      "XGBoost: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100}\n",
      "LightGBM: {'learning_rate': 0.05, 'n_estimators': 100, 'num_leaves': 31}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "754092a468eca661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T16:08:40.757982Z",
     "start_time": "2024-12-03T16:08:39.770743Z"
    }
   },
   "source": [
    "\n",
    "baseline_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=10),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=10),\n",
    "    \"SVM\": SVC(random_state=10),\n",
    "    \"XGBoost\": XGBClassifier(random_state=10, eval_metric='logloss'),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=10)\n",
    "}\n",
    "\n",
    "optimized_models = {\n",
    "    \"Logistic Regression\": logistic_search.best_estimator_,\n",
    "    \"Random Forest\": rf_search.best_estimator_,\n",
    "    \"SVM\": svm_search.best_estimator_,\n",
    "    \"XGBoost\": xgb_search.best_estimator_,\n",
    "    \"LightGBM\": lgbm_search.best_estimator_\n",
    "}\n",
    "\n",
    "baseline_results = {}\n",
    "optimized_results = {}\n",
    "\n",
    "for name, model in baseline_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    baseline_results[name] = {\"Accuracy\": accuracy, \"F1 Score\": f1}\n",
    "\n",
    "for name, (model, params) in optimized_models.items():\n",
    "    grid_search = GridSearchCV(model, params, cv=5, scoring='f1', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    optimized_results[name] = {\"Accuracy\": accuracy, \"F1 Score\": f1, \"model\": best_model, \"grid_search\": grid_search}\n",
    "\n",
    "baseline_df = pd.DataFrame(baseline_results).T\n",
    "optimized_df = pd.DataFrame(optimized_results).T"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 1124, number of negative: 2599\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 54\n",
      "[LightGBM] [Info] Number of data points in the train set: 3723, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.301907 -> initscore=-0.838233\n",
      "[LightGBM] [Info] Start training from score -0.838233\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable LogisticRegression object",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 27\u001B[0m\n\u001B[1;32m     24\u001B[0m     f1 \u001B[38;5;241m=\u001B[39m f1_score(y_test, y_pred, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     25\u001B[0m     baseline_results[name] \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m: accuracy, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mF1 Score\u001B[39m\u001B[38;5;124m\"\u001B[39m: f1}\n\u001B[0;32m---> 27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, (model, params) \u001B[38;5;129;01min\u001B[39;00m optimized_models\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m     28\u001B[0m     grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(model, params, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m'\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     29\u001B[0m     grid_search\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n",
      "\u001B[0;31mTypeError\u001B[0m: cannot unpack non-iterable LogisticRegression object"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T16:08:40.758873Z",
     "start_time": "2024-12-03T16:08:40.758825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print(\"Baseline results:\\n\")\n",
    "print(tabulate(baseline_df, headers=\"keys\", tablefmt=\"pretty\"))\n",
    "\n",
    "print(\"\\nOptimized results:\\n\")\n",
    "print(tabulate(optimized_df, headers=\"keys\", tablefmt=\"pretty\"))"
   ],
   "id": "5699c8ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "65826f21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T16:08:40.759572Z",
     "start_time": "2024-12-03T16:08:40.759531Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics = ['Accuracy', 'F1 Score']\n",
    "\n",
    "def plot_comparison(baseline_df, optimized_df):\n",
    "    x = np.arange(len(baseline_df))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        baseline_values = baseline_df[metric]\n",
    "        optimized_values = optimized_df[metric]\n",
    "\n",
    "        axes[i].bar(x - width/2, baseline_values, width, label='Baseline', alpha=0.7)\n",
    "        axes[i].bar(x + width/2, optimized_values, width, label='Optimized', alpha=0.7, color='orange')\n",
    "\n",
    "        axes[i].set_title(f\"{metric} Comparison\")\n",
    "        axes[i].set_ylabel(metric)\n",
    "        axes[i].set_xticks(x)\n",
    "        axes[i].set_xticklabels(baseline_df.index, rotation=45)\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(axis='y')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_comparison(baseline_df, optimized_df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f4579f41",
   "metadata": {},
   "source": [
    "def plot_confusion_matrices(optimized_models, X_test, y_test):\n",
    "    for name, model in optimized_models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.title(f\"Confusion Matrix: {name} (Optimized)\")\n",
    "        plt.show()\n",
    "\n",
    "plot_confusion_matrices(optimized_models, X_test, y_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_cv_scores(results):\n",
    "    cv_results = []\n",
    "    for name, metrics in results.items():\n",
    "        grid_search = metrics['grid_search']\n",
    "        scores = grid_search.cv_results_['mean_test_score']\n",
    "        for score in scores:\n",
    "            cv_results.append({'Model': name, 'F1 Score': score})\n",
    "\n",
    "    cv_results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(x='Model', y='F1 Score', data=cv_results_df)\n",
    "    plt.title('Cross-Validation F1 Scores for Different Models')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y', linestyle='--', linewidth=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "1f061d3aaa166df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_cv_scores(optimized_results)",
   "id": "535f0ab0c04141fb",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
